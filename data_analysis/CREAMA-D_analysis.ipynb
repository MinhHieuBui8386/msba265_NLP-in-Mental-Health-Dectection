{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path = 'C:/Users/Admin/Documents/GitHub/msba265-finalstorage/data_storage/CREAMA-D/AudioWAV'\n",
    "if not os.path.exists(path):\n",
    "    raise FileNotFoundError(f\"Path does not exist: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect audio file paths and emotions\n",
    "audio_path = []\n",
    "audio_emotion = []\n",
    "print(\"Collecting audio file paths and extracting emotions...\")\n",
    "for audio in os.listdir(path):\n",
    "    full_path = os.path.join(path, audio)\n",
    "    if os.path.isfile(full_path):\n",
    "        audio_path.append(full_path)\n",
    "        emotion = audio.split('_')[2]\n",
    "        emotion_map = {\n",
    "            \"SAD\": \"sad\",\n",
    "            \"ANG\": \"angry\",\n",
    "            \"DIS\": \"disgust\",\n",
    "            \"NEU\": \"neutral\",\n",
    "            \"HAP\": \"happy\",\n",
    "            \"FEA\": \"fear\"\n",
    "        }\n",
    "        audio_emotion.append(emotion_map.get(emotion, \"unknown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "emotion_dataset = pd.DataFrame(audio_emotion, columns=['Emotions'])\n",
    "audio_path_dataset = pd.DataFrame(audio_path, columns=['Path'])\n",
    "dataset = pd.concat([audio_path_dataset, emotion_dataset], axis=1)\n",
    "print(f\"Dataset created with {len(dataset)} entries.\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(dataset.info())\n",
    "print(\"Emotion distribution:\\n\", dataset['Emotions'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Emotion Distribution\n",
    "plt.figure(figsize=(6, 6), dpi=80)\n",
    "sns.histplot(dataset.Emotions, color='#F19C0E')\n",
    "plt.title(\"Emotion Count\", size=16)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balance with Percentage\n",
    "print(\"\\n--- Class Balance with Percentage ---\")\n",
    "emotion_counts = dataset['Emotions'].value_counts()\n",
    "emotion_percentages = (emotion_counts / len(dataset)) * 100\n",
    "\n",
    "# Create a dataframe for plotting\n",
    "emotion_dist = pd.DataFrame({\n",
    "    'Emotion': emotion_counts.index,\n",
    "    'Count': emotion_counts.values,\n",
    "    'Percentage': emotion_percentages.values\n",
    "})\n",
    "\n",
    "# Plot count and percentage\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=emotion_dist, x='Emotion', y='Count', palette='muted')\n",
    "for i, row in emotion_dist.iterrows():\n",
    "    plt.text(i, row['Count'] + 1, f\"{row['Percentage']:.1f}%\", ha='center', fontsize=10)\n",
    "\n",
    "plt.title(\"Emotion Class Distribution (Count & Percentage)\", fontsize=16)\n",
    "plt.xlabel(\"Emotions\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Print the emotion distribution wi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Duration Analysis\n",
    "print(\"\\n--- File Duration Analysis ---\")\n",
    "durations = []\n",
    "for path in dataset['Path']:\n",
    "    try:\n",
    "        data, sr = librosa.load(path, sr=None)\n",
    "        durations.append(len(data) / sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {path}: {e}\")\n",
    "dataset['Duration'] = durations\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(durations, bins=20, kde=True, color='blue')\n",
    "plt.title(\"Distribution of Audio Durations\", fontsize=16)\n",
    "plt.xlabel(\"Duration (seconds)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Feature Analysis (MFCC Example)\n",
    "print(\"\\n--- Audio Feature Analysis ---\")\n",
    "for emotion in dataset['Emotions'].unique():\n",
    "    sample_path = dataset[dataset['Emotions'] == emotion].iloc[0]['Path']\n",
    "    try:\n",
    "        data, sr = librosa.load(sample_path, sr=16000)\n",
    "        mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(mfcc, x_axis='time', cmap='coolwarm')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"MFCCs for {emotion.capitalize()} Emotion\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing MFCC for {emotion}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for waveplot and spectrogram visualization\n",
    "def plot_wave_and_spectrogram(file_path, emotion):\n",
    "    try:\n",
    "        data, sampling_rate = librosa.load(file_path, sr=16000)  # Consistent sampling rate\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f\"Waveplot for {emotion.capitalize()} Emotion\", size=16)\n",
    "        librosa.display.waveshow(data, sr=sampling_rate)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.title(f\"Spectrogram for {emotion.capitalize()} Emotion\", size=16)\n",
    "        D = librosa.stft(data)\n",
    "        S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "        librosa.display.specshow(S_db, sr=sampling_rate, x_axis='time', y_axis='hz', cmap='viridis')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample file for the 'sad' emotion\n",
    "sad_files = dataset[dataset['Emotions'] == 'sad']['Path']\n",
    "if not sad_files.empty:\n",
    "    sample_file = sad_files.values[0]\n",
    "    print(f\"Processing file: {sample_file}\")\n",
    "    plot_wave_and_spectrogram(sample_file, \"sad\")\n",
    "else:\n",
    "    print(\"No files with 'sad' emotion found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection\n",
    "print(\"\\n--- Outlier Detection ---\")\n",
    "duration_threshold = dataset['Duration'].quantile(0.99)\n",
    "duration_outliers = dataset[dataset['Duration'] > duration_threshold]\n",
    "print(f\"Files with duration above {duration_threshold:.2f} seconds:\")\n",
    "print(duration_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def extract_features(dataset, target_length=5000):\n",
    "    X, Y = [], []\n",
    "    print(\"Extracting features from audio files...\")\n",
    "    for path, emotion in zip(dataset['Path'], dataset['Emotions']):\n",
    "        try:\n",
    "            # Load audio file with consistent sampling rate\n",
    "            value, sample_rate = librosa.load(path, sr=16000)\n",
    "\n",
    "            # Add noise to audio\n",
    "            noise_amp = 0.035 * np.random.uniform() * np.amax(value)\n",
    "            value = value + noise_amp * np.random.normal(size=value.shape[0])\n",
    "\n",
    "            # Extract MFCC features\n",
    "            mfcc = librosa.feature.mfcc(y=value, sr=sample_rate, n_mfcc=13, n_fft=200, hop_length=512)\n",
    "            mfcc = mfcc.T.flatten()\n",
    "\n",
    "            # Extract Mel Spectrogram features\n",
    "            mel = librosa.feature.melspectrogram(y=value, sr=sample_rate, hop_length=256, n_fft=512, n_mels=64)\n",
    "            mel = librosa.power_to_db(mel ** 2).T.flatten()\n",
    "\n",
    "            # Combine features\n",
    "            features = np.hstack((mfcc, mel))\n",
    "\n",
    "            # Pad or truncate features to ensure consistent length\n",
    "            if len(features) > target_length:\n",
    "                features = features[:target_length]\n",
    "            else:\n",
    "                features = np.pad(features, (0, max(0, target_length - len(features))), 'constant')\n",
    "\n",
    "            X.append(features)\n",
    "            Y.append(emotion)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {path}: {e}\")\n",
    "\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from a subset of the dataset (demo with first 50 samples)\n",
    "X, Y = extract_features(dataset.head(50))\n",
    "if X.size > 0:\n",
    "    print(f\"Features extracted: {X.shape}\")\n",
    "    extracted_audio_df = pd.DataFrame(X)\n",
    "    extracted_audio_df[\"Emotion\"] = Y\n",
    "    print(extracted_audio_df.head())\n",
    "else:\n",
    "    print(\"No features extracted. Check your dataset or file paths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation Check\n",
    "print(\"\\n--- Cross-Validation Check ---\")\n",
    "train, test = train_test_split(dataset, test_size=0.2, stratify=dataset['Emotions'], random_state=42)\n",
    "print(f\"Training set size: {len(train)}\")\n",
    "print(f\"Test set size: {len(test)}\")\n",
    "print(\"\\nTraining set class distribution:\\n\", train['Emotions'].value_counts())\n",
    "print(\"\\nTest set class distribution:\\n\", test['Emotions'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
